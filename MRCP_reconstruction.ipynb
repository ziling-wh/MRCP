{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIfTI file: /Users/ziling/Desktop/MRCP/public_dataset/data1_0_slice_public_dataset.nii.gz\n",
      "Saved NIfTI file: /Users/ziling/Desktop/MRCP/public_dataset/data1_1_slice_public_dataset.nii.gz\n",
      "Saved NIfTI file: /Users/ziling/Desktop/MRCP/public_dataset/data1_2_slice_public_dataset.nii.gz\n",
      "Sample: data1.h5, Slice: 0\n",
      "Sample: data1.h5, Slice: 1\n",
      "Sample: data1.h5, Slice: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional, Union, List, Tuple\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import fastmri.data.utils as utils\n",
    "import pandas as pd\n",
    "\n",
    "def filter_data(dataset: pd.DataFrame, root: Union[str, Path], data_partition: str) -> List[Path]:\n",
    "    \"\"\"\n",
    "    根据数据分区过滤文件列表。\n",
    "\n",
    "    Args:\n",
    "        dataset: 包含数据文件和分区信息的 pandas DataFrame。\n",
    "        root: 数据集的根目录。\n",
    "        data_partition: 数据分区，\"train\"、\"val\"或\"test\"。\n",
    "    \n",
    "    Returns:\n",
    "        对应数据分区的文件路径列表。\n",
    "    \"\"\"\n",
    "    # 使用 'Split' 列过滤属于指定数据分区的文件\n",
    "    filtered_files = dataset[dataset['Split'] == data_partition]['Name']\n",
    "\n",
    "    # 将文件名转换为完整路径并加上扩展名\n",
    "    file_list = [Path(root) / (fname + '.h5') for fname in filtered_files]\n",
    "\n",
    "    return file_list\n",
    "\n",
    "def get_file_list(root: Union[str, Path, os.PathLike], data_partition: str) -> List[Path]:\n",
    "    \"\"\"\n",
    "    获取指定数据分区的文件列表。\n",
    "\n",
    "    Args:\n",
    "        root: 数据集的根路径。\n",
    "        data_partition: 数据分区，\"train\"、\"val\"或\"test\"。\n",
    "    \n",
    "    Returns:\n",
    "        文件路径的列表。\n",
    "    \"\"\"\n",
    "    root = Path(root)  # 将 root 转换为 Path 对象\n",
    "\n",
    "    # 假设你的 dataset.csv 文件在 root 目录中\n",
    "    dataset = pd.read_csv(\"/Users/ziling/Desktop/MRCP/MRCP_DLRecon-main/sample_data/dataset.csv\")\n",
    "\n",
    "    # 根据 data_partition 过滤文件列表，假设 filter_data 是你用来过滤数据的函数\n",
    "    file_list = filter_data(dataset, root, data_partition)\n",
    "\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def retrieve_metadata(fname: Union[str, Path, os.PathLike]) -> int:\n",
    "    \"\"\"\n",
    "    获取文件的切片数量。\n",
    "    \n",
    "    Args:\n",
    "        fname: 文件路径。\n",
    "    \n",
    "    Returns:\n",
    "        文件中的切片数量。\n",
    "    \"\"\"\n",
    "    with h5py.File(fname, \"r\") as hf:\n",
    "        num_slices = hf[\"kdata\"].shape[-1]\n",
    "    return num_slices\n",
    "\n",
    "\n",
    "def load_slice_data(fname: Union[str, Path, os.PathLike], dataslice: int) -> Tuple:\n",
    "    \"\"\"\n",
    "    从文件中加载指定切片的数据，包括k空间、重建结果和敏感度图。\n",
    "\n",
    "    Args:\n",
    "        fname: 文件路径。\n",
    "        dataslice: 要加载的切片索引。\n",
    "    \n",
    "    Returns:\n",
    "        k空间数据、GRAPPA重建结果、敏感度图、文件属性和基础加速因子。\n",
    "    \"\"\"\n",
    "    with h5py.File(fname, \"r\") as hf:\n",
    "        kspace = hf[\"kdata\"][..., dataslice]  # k空间数据\n",
    "        target = hf[\"grappa\"][..., dataslice]  # GRAPPA重建结果\n",
    "        sens_maps = hf[\"sm_espirit\"][..., dataslice]  # 敏感度图\n",
    "        \n",
    "        attrs = dict(hf.attrs)\n",
    "        base_acc = attrs.get('base_acc', 1)  # 基础加速因子，默认为1（可以是2或6）\n",
    "        \n",
    "    return kspace, target, sens_maps, base_acc, attrs\n",
    "\n",
    "\n",
    "def create_examples(file_list: List[Path]) -> List[Tuple[Path, int]]:\n",
    "    \"\"\"\n",
    "    为每个文件生成切片示例。\n",
    "    \n",
    "    Args:\n",
    "        file_list: 文件列表。\n",
    "    \n",
    "    Returns:\n",
    "        文件和对应的切片索引的列表。\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for fname in sorted(file_list):\n",
    "        num_slices = retrieve_metadata(fname)\n",
    "        examples += [(fname, slice_idx) for slice_idx in range(num_slices)]\n",
    "    return examples\n",
    "\n",
    "\n",
    "def load_dataset(root: Union[str, Path, os.PathLike], data_partition: str = \"train\", is_prototype: bool = False) -> List[Tuple[Path, int]]:\n",
    "    \"\"\"\n",
    "    加载数据集，生成所有文件及其切片的列表。\n",
    "\n",
    "    Args:\n",
    "        root: 数据集的根目录。\n",
    "        data_partition: 数据分区，默认为 \"train\"。\n",
    "        is_prototype: 是否只加载少量数据用于调试。\n",
    "\n",
    "    Returns:\n",
    "        文件和切片索引的列表。\n",
    "    \"\"\"\n",
    "    files = get_file_list(root, data_partition)\n",
    "\n",
    "    # 如果是原型模式，则只使用部分数据\n",
    "    if is_prototype:\n",
    "        files = files[:1]  # 调试时只使用第一个文件\n",
    "\n",
    "    examples = create_examples(files)\n",
    "    return examples\n",
    "\n",
    "\n",
    "def convert_to_nifti(kspace: np.ndarray, target: np.ndarray, sens_maps: np.ndarray, output_dir: Union[str, Path], file_info: List[str]):\n",
    "    \"\"\"\n",
    "    将从 h5 文件中提取的 MRI 数据转换为 NIfTI 格式并保存到指定目录。\n",
    "\n",
    "    Args:\n",
    "        kspace: 原始的 k-space 数据。\n",
    "        target: 重建后的图像（如 GRAPPA）。\n",
    "        sens_maps: 敏感度图数据。\n",
    "        output_dir: 保存 NIfTI 文件的目录。\n",
    "        file_info: 文件信息，包括文件名和切片号。\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)  # 确保输出目录存在\n",
    "\n",
    "    # 生成文件名\n",
    "    file_name = f\"{file_info[0]}_slice_{file_info[1]}.nii.gz\"\n",
    "\n",
    "    # 将 GRAPPA重建图像保存为 NIfTI 格式\n",
    "    nii_img = nib.Nifti1Image(target, affine=np.eye(4))  # 假设 affine 矩阵为单位矩阵，可以根据需要修改\n",
    "    output_path = output_dir / file_name\n",
    "    nib.save(nii_img, str(output_path))\n",
    "\n",
    "    print(f\"Saved NIfTI file: {output_path}\")\n",
    "\n",
    "\n",
    "def transform(kspace, target, target_acc, base_acc, fname, dataslice, sens_maps, dinfo):\n",
    "    \"\"\"\n",
    "    数据转换函数，将 h5 数据提取并转换为 NIfTI 格式。\n",
    "    \n",
    "    Args:\n",
    "        kspace: k-space 数据。\n",
    "        target: 重建后的图像数据。\n",
    "        target_acc: 目标加速因子。\n",
    "        base_acc: 基础加速因子。\n",
    "        fname: 文件名。\n",
    "        dataslice: 切片编号。\n",
    "        sens_maps: 敏感度图。\n",
    "        dinfo: 文件信息，包含文件名和文件夹名。\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    output_dir = \"/Users/ziling/Desktop/MRCP/public_dataset/\"  # 设定你想保存NIfTI文件的目录\n",
    "\n",
    "    # 调用转换函数，将数据保存为NIfTI格式\n",
    "    convert_to_nifti(kspace, target, sens_maps, output_dir, dinfo)\n",
    "    \n",
    "    # 可以返回其他内容作为必要的信息，如果需要处理其他部分\n",
    "    return {\"filename\": fname, \"slice\": dataslice}\n",
    "\n",
    "\n",
    "def get_sample(examples: List[Tuple[Path, int]], idx: int, transform: Callable, target_acc: int) -> dict:\n",
    "    \"\"\"\n",
    "    获取指定索引的数据样本。\n",
    "\n",
    "    Args:\n",
    "        examples: 文件和切片的列表。\n",
    "        idx: 样本索引。\n",
    "        transform: 数据变换函数。\n",
    "        target_acc: 目标加速因子。\n",
    "    \n",
    "    Returns:\n",
    "        经过变换后的样本。\n",
    "    \"\"\"\n",
    "    fname, dataslice = examples[idx]\n",
    "    kspace, target, sens_maps, base_acc, attrs = load_slice_data(fname, dataslice)\n",
    "\n",
    "    dinfo = [f\"{fname.stem}_{dataslice}\", fname.parent.stem]  # 文件和切片信息\n",
    "    sample = transform(kspace, target, target_acc, base_acc, fname.name, dataslice, sens_maps, dinfo)\n",
    "\n",
    "    return sample\n",
    "\n",
    "def get_samples(examples: List[Tuple[Path, int]], indices: List[int], transform: Callable, target_acc: int) -> List[dict]:\n",
    "    \"\"\"\n",
    "    获取指定索引的多个数据样本。\n",
    "\n",
    "    Args:\n",
    "        examples: 文件和切片的列表。\n",
    "        indices: 样本索引的列表（可以是多个索引）。\n",
    "        transform: 数据变换函数。\n",
    "        target_acc: 目标加速因子。\n",
    "    \n",
    "    Returns:\n",
    "        经过变换后的样本的列表。\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    for idx in indices:\n",
    "        fname, dataslice = examples[idx]\n",
    "        kspace, target, sens_maps, base_acc, attrs = load_slice_data(fname, dataslice)\n",
    "\n",
    "        dinfo = [f\"{fname.stem}_{dataslice}\", fname.parent.stem]  # 文件和切片信息\n",
    "        sample = transform(kspace, target, target_acc, base_acc, fname.name, dataslice, sens_maps, dinfo)\n",
    "        samples.append(sample)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# 示例使用\n",
    "root_dir = \"/Users/ziling/Desktop/MRCP/public_dataset/\"\n",
    "data_partition = \"train\"\n",
    "target_acc = 6\n",
    "is_prototype = False\n",
    "\n",
    "# 加载数据集\n",
    "examples = load_dataset(root_dir, data_partition, is_prototype)\n",
    "# 获取并转换数据集中的多个样本\n",
    "sample_indices = [0, 1, 2]  # 获取前三个样本（假设存在多个样本）\n",
    "samples = get_samples(examples, sample_indices, transform, target_acc)\n",
    "\n",
    "# 打印样本信息\n",
    "for sample in samples:\n",
    "    print(f\"Sample: {sample['filename']}, Slice: {sample['slice']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomics_envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
